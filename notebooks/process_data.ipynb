{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96a65ab4-110e-4ae2-a4e0-fbce1f216e02",
   "metadata": {},
   "source": [
    "### Processing the word sets for the experimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0952cfea-df93-40b6-9026-633e3b44efff",
   "metadata": {},
   "source": [
    "### CORPES XXI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7552b094-aacf-4046-a32f-7eea624fe0bb",
   "metadata": {},
   "source": [
    "Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e01594f-193c-4ff0-b26c-e1e31f00fed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words have been extracted and saved to: ../data/sets_palabras/ES/gram/CORPES_f_clean.txt\n"
     ]
    }
   ],
   "source": [
    "input_file = \"../data/sets_palabras/ES/gram/CORPES_f.txt\"  \n",
    "output_file = \"../data/sets_palabras/ES/gram/CORPES_f_clean.txt\"  \n",
    "\n",
    "# Open the file and process each line\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as infile, open(output_file, \"w\", encoding=\"utf-8\") as outfile:\n",
    "    for line in infile:\n",
    "        # Split the line by tabs and take the first element\n",
    "        word = line.split(\"\\t\")[0].lower()\n",
    "        # Write the word to the output file\n",
    "        outfile.write(word + \"\\n\")\n",
    "\n",
    "print(\"Words have been extracted and saved to:\", output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "449f1d4c-a4a6-40b4-a9ad-0a9f4894ee2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words have been extracted and saved to: ../data/sets_palabras/ES/gram/CORPES_m_clean.txt\n"
     ]
    }
   ],
   "source": [
    "input_file = \"../data/sets_palabras/ES/gram/CORPES_m.txt\"  \n",
    "output_file = \"../data/sets_palabras/ES/gram/CORPES_m_clean.txt\"  \n",
    "\n",
    "# Open the file and process each line\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as infile, open(output_file, \"w\", encoding=\"utf-8\") as outfile:\n",
    "    for line in infile:\n",
    "        # Split the line by tabs and take the first element\n",
    "        word = line.split(\"\\t\")[0].lower()\n",
    "        # Write the word to the output file\n",
    "        outfile.write(word + \"\\n\")\n",
    "\n",
    "print(\"Words have been extracted and saved to:\", output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e723b9-f5c8-424b-a7a5-b9845a1392f3",
   "metadata": {},
   "source": [
    "Filter adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bf6af6-ee95-4aeb-aa28-1fe8b53af784",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "ES_emb_model = KeyedVectors.load('../data/embeddings/keyedvectors/model_esp.kv', mmap='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c154369-e408-4d65-bb9f-1f4832ea6ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words have been extracted and saved to: ../data/sets_palabras/ES/gram/ES_ADJ_sg_f_test.txt\n"
     ]
    }
   ],
   "source": [
    "input_file = \"../data/sets_palabras/ES/gram/CORPES_f.txt\"  \n",
    "output_file = \"../data/sets_palabras/ES/gram/ES_ADJ_sg_f_test.txt\"  \n",
    "\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as infile, open(output_file, \"w\", encoding=\"utf-8\") as outfile:\n",
    "    for line in infile:\n",
    "        word = line.split(\"\\t\")[0]\n",
    "        if word.isalpha() and word in ES_emb_model and word.endswith(\"a\"):\n",
    "            outfile.write(word + \"\\n\")\n",
    "\n",
    "print(\"Words have been extracted and saved to:\", output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c7b12b2-0163-4f1c-b438-86d4786e5b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words have been extracted and saved to: ../data/sets_palabras/ES/gram/ES_ADJ_sg_m_test.txt\n"
     ]
    }
   ],
   "source": [
    "input_file = \"../data/sets_palabras/ES/gram/CORPES_m.txt\"  \n",
    "output_file = \"../data/sets_palabras/ES/gram/ES_ADJ_sg_m_test.txt\"  \n",
    "\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as infile, open(output_file, \"w\", encoding=\"utf-8\") as outfile:\n",
    "    for line in infile:\n",
    "        word = line.split(\"\\t\")[0]\n",
    "        if word.isalpha() and word in ES_emb_model and word.endswith(\"o\"):\n",
    "            outfile.write(word + \"\\n\")\n",
    "\n",
    "print(\"Words have been extracted and saved to:\", output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb135348-2c39-42aa-a5a2-e25d93a19727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words have been extracted and saved to: ../data/sets_palabras/ES/gram/ES_ADJ_pl_m_test.txt\n"
     ]
    }
   ],
   "source": [
    "input_file = \"../data/sets_palabras/ES/gram/CORPES_m.txt\"  \n",
    "output_file = \"../data/sets_palabras/ES/gram/ES_ADJ_pl_m_test.txt\"  \n",
    "\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as infile, open(output_file, \"w\", encoding=\"utf-8\") as outfile:\n",
    "    for line in infile:\n",
    "        word = line.split(\"\\t\")[0]\n",
    "        if word.isalpha() and word in ES_emb_model and word.endswith(\"os\"):\n",
    "            outfile.write(word + \"\\n\")\n",
    "\n",
    "print(\"Words have been extracted and saved to:\", output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1edd9fe-5c55-4120-b94d-242303e33cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words have been extracted and saved to: ../data/sets_palabras/ES/gram/ES_ADJ_pl_f_test.txt\n"
     ]
    }
   ],
   "source": [
    "input_file = \"../data/sets_palabras/ES/gram/CORPES_f.txt\"  \n",
    "output_file = \"../data/sets_palabras/ES/gram/ES_ADJ_pl_f_test.txt\"  \n",
    "\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as infile, open(output_file, \"w\", encoding=\"utf-8\") as outfile:\n",
    "    for line in infile:\n",
    "        word = line.split(\"\\t\")[0]\n",
    "        if word.isalpha() and word in ES_emb_model and word.endswith(\"as\"):\n",
    "            outfile.write(word + \"\\n\")\n",
    "\n",
    "print(\"Words have been extracted and saved to:\", output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e994cde7-b8a2-436a-be4c-747794acb5af",
   "metadata": {},
   "source": [
    "Filter nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c367421-fbf1-46cc-815b-2b7dd1a96a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "ES_emb_model = KeyedVectors.load('../data/embeddings/keyedvectors/model_esp.kv', mmap='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb735140-b2be-4cae-b599-35d4c28b1322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words have been extracted and saved to: ../data/sets_palabras/ES/gram/ES_NOUN_sg_m_test.txt\n"
     ]
    }
   ],
   "source": [
    "input_file = \"../data/sets_palabras/ES/gram/CORPES_m.txt\"  \n",
    "output_file = \"../data/sets_palabras/ES/gram/ES_NOUN_sg_m_test.txt\" \n",
    "\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as infile, open(output_file, \"w\", encoding=\"utf-8\") as outfile:\n",
    "    for line in infile:\n",
    "        word = line.split(\"\\t\")[0]\n",
    "        if word.isalpha() and word in ES_emb_model and not word.endswith(\"a\"):\n",
    "            outfile.write(word + \"\\n\")\n",
    "\n",
    "print(\"Words have been extracted and saved to:\", output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26f9a6f1-01fd-4a97-b87e-864e2b5c21f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words have been extracted and saved to: ../data/sets_palabras/ES/gram/ES_NOUN_sg_f_test.txt\n"
     ]
    }
   ],
   "source": [
    "input_file = \"../data/sets_palabras/ES/gram/CORPES_f.txt\"  \n",
    "output_file = \"../data/sets_palabras/ES/gram/ES_NOUN_sg_f_test.txt\" \n",
    "\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as infile, open(output_file, \"w\", encoding=\"utf-8\") as outfile:\n",
    "    for line in infile:\n",
    "        word = line.split(\"\\t\")[0]\n",
    "        if word.isalpha() and word in ES_emb_model and not word.endswith(\"o\"):\n",
    "            outfile.write(word + \"\\n\")\n",
    "\n",
    "print(\"Words have been extracted and saved to:\", output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef6d48f5-efad-4676-9c36-462aeca31887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words have been extracted and saved to: ../data/sets_palabras/ES/gram/ES_NOUN_pl_m_test.txt\n"
     ]
    }
   ],
   "source": [
    "input_file = \"../data/sets_palabras/ES/gram/CORPES_m.txt\"  \n",
    "output_file = \"../data/sets_palabras/ES/gram/ES_NOUN_pl_m_test.txt\" \n",
    "\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as infile, open(output_file, \"w\", encoding=\"utf-8\") as outfile:\n",
    "    for line in infile:\n",
    "        word = line.split(\"\\t\")[0]\n",
    "        if word.isalpha() and word in ES_emb_model and not word.endswith(\"as\"):\n",
    "            outfile.write(word + \"\\n\")\n",
    "\n",
    "print(\"Words have been extracted and saved to:\", output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d3590dc-6d47-449c-8736-5c180f7389d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words have been extracted and saved to: ../data/sets_palabras/ES/gram/ES_NOUN_pl_m.txt\n"
     ]
    }
   ],
   "source": [
    "# Input file path\n",
    "input_file = \"../data/sets_palabras/ES/gram/CORPES_m.txt\"  \n",
    "output_file = \"../data/sets_palabras/ES/gram/ES_NOUN_pl_m.txt\"   # Output file path\n",
    "\n",
    "# Open the file and process each line\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as infile, open(output_file, \"w\", encoding=\"utf-8\") as outfile:\n",
    "    for line in infile:\n",
    "        # Split the line by tabs and take the first element\n",
    "        word = line.split(\"\\t\")[0]\n",
    "        if word.isalpha():\n",
    "            outfile.write(word + \"\\n\")\n",
    "\n",
    "print(\"Words have been extracted and saved to:\", output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b701061-4a87-496f-9dd4-f8cde9a1d084",
   "metadata": {},
   "source": [
    "### ES_gram_LDA_f (34784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75d90fe8-7bea-4e57-8b68-5d56f0f76f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alternated words have been saved to: ../data/sets_palabras/ES/gram/ES_gram_LDA_f.txt\n"
     ]
    }
   ],
   "source": [
    "# Input file paths\n",
    "file1 = \"../data/sets_palabras/ES/gram/ES_NOUN_sg_f.txt\"\n",
    "file2 = \"../data/sets_palabras/ES/gram/ES_ADJ_pl_f.txt\"\n",
    "file3 = \"../data/sets_palabras/ES/gram/ES_NOUN_pl_f.txt\"\n",
    "file4 = \"../data/sets_palabras/ES/gram/ES_ADJ_sg_f.txt\"\n",
    "\n",
    "output_file = \"../data/sets_palabras/ES/gram/ES_gram_LDA_f.txt\"\n",
    "\n",
    "\n",
    "with open(file1, \"r\", encoding=\"utf-8\") as f1, \\\n",
    "        open(file2, \"r\", encoding=\"utf-8\") as f2, \\\n",
    "        open(file3, \"r\", encoding=\"utf-8\") as f3, \\\n",
    "        open(file4, \"r\", encoding=\"utf-8\") as f4, \\\n",
    "        open(output_file, \"w\", encoding=\"utf-8\") as outfile:\n",
    "        \n",
    "        words1 = [line.strip() for line in f1 if line.strip()]\n",
    "        words2 = [line.strip() for line in f2 if line.strip()]\n",
    "        words3 = [line.strip() for line in f3 if line.strip()]\n",
    "        words4 = [line.strip() for line in f4 if line.strip()]\n",
    "\n",
    "            \n",
    "        alternated_words = []\n",
    "        for w1, w2, w3, w4 in zip(words1, words2, words3, words4):\n",
    "            w1 = w1.lower()\n",
    "            w2 = w2.lower()\n",
    "            w3 = w3.lower()\n",
    "            w4 = w4.lower()\n",
    "            alternated_words.append(w1)\n",
    "            alternated_words.append(w2)\n",
    "            alternated_words.append(w3)\n",
    "            alternated_words.append(w4)\n",
    "\n",
    "        outfile.write(\"\\n\".join(alternated_words))\n",
    "\n",
    "print(\"Alternated words have been saved to:\", output_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f8d502-6a5e-4e7a-96aa-24d52d436496",
   "metadata": {},
   "source": [
    "### ES_gram_LDA_m (29716)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0ede049-0aaf-4d34-b7e4-29fcb0fb712a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alternated words have been saved to: ../data/sets_palabras/ES/gram/ES_gram_LDA_m.txt\n"
     ]
    }
   ],
   "source": [
    "# Input file paths\n",
    "file1 = \"../data/sets_palabras/ES/gram/ES_NOUN_sg_m.txt\"\n",
    "file2 = \"../data/sets_palabras/ES/gram/ES_ADJ_pl_m.txt\"\n",
    "file3 = \"../data/sets_palabras/ES/gram/ES_NOUN_pl_m.txt\"\n",
    "file4 = \"../data/sets_palabras/ES/gram/ES_ADJ_sg_m.txt\"\n",
    "\n",
    "output_file = \"../data/sets_palabras/ES/gram/ES_gram_LDA_m.txt\"\n",
    "\n",
    "\n",
    "with open(file1, \"r\", encoding=\"utf-8\") as f1, \\\n",
    "        open(file2, \"r\", encoding=\"utf-8\") as f2, \\\n",
    "        open(file3, \"r\", encoding=\"utf-8\") as f3, \\\n",
    "        open(file4, \"r\", encoding=\"utf-8\") as f4, \\\n",
    "        open(output_file, \"w\", encoding=\"utf-8\") as outfile:\n",
    "        \n",
    "        words1 = [line.strip() for line in f1 if line.strip()]\n",
    "        words2 = [line.strip() for line in f2 if line.strip()]\n",
    "        words3 = [line.strip() for line in f3 if line.strip()]\n",
    "        words4 = [line.strip() for line in f4 if line.strip()]\n",
    "    \n",
    "        alternated_words = []\n",
    "        for w1, w2, w3, w4 in zip(words1, words2, words3, words4):\n",
    "            w1 = w1.lower()\n",
    "            w2 = w2.lower()\n",
    "            w3 = w3.lower()\n",
    "            w4 = w4.lower()\n",
    "            alternated_words.append(w1)\n",
    "            alternated_words.append(w2)\n",
    "            alternated_words.append(w3)\n",
    "            alternated_words.append(w4)\n",
    "\n",
    "        outfile.write(\"\\n\".join(alternated_words))\n",
    "\n",
    "print(\"Alternated words have been saved to:\", output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8996ee55-9156-448d-b84c-85ab80a91194",
   "metadata": {},
   "source": [
    "### ES_GGCTest_m (100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3b425eed-95bf-4bbe-bd13-e37646129d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alternated words have been saved to: ../data/sets_palabras/ES/gram/ES_GGCTest_m.txt\n"
     ]
    }
   ],
   "source": [
    "file1 = \"../data/sets_palabras/ES/gram/ES_NOUN_sg_m_test.txt\"\n",
    "file2 = \"../data/sets_palabras/ES/gram/ES_ADJ_pl_m_test.txt\"\n",
    "file3 = \"../data/sets_palabras/ES/gram/ES_NOUN_pl_m_test.txt\"\n",
    "file4 = \"../data/sets_palabras/ES/gram/ES_ADJ_sg_m_test.txt\"\n",
    "\n",
    "output_file = \"../data/sets_palabras/ES/gram/ES_GGCTest_m.txt\"\n",
    "\n",
    "with open(file1, \"r\", encoding=\"utf-8\") as f1, \\\n",
    "        open(file2, \"r\", encoding=\"utf-8\") as f2, \\\n",
    "        open(file3, \"r\", encoding=\"utf-8\") as f3, \\\n",
    "        open(file4, \"r\", encoding=\"utf-8\") as f4, \\\n",
    "        open(output_file, \"w\", encoding=\"utf-8\") as outfile:\n",
    "            \n",
    "        words1 = [line.strip() for line in f1 if line.strip()]\n",
    "        words2 = [line.strip() for line in f2 if line.strip()]\n",
    "        words3 = [line.strip() for line in f3 if line.strip()]\n",
    "        words4 = [line.strip() for line in f4 if line.strip()]\n",
    "    \n",
    "        alternated_words = []\n",
    "        for w1, w2, w3, w4 in zip(words1, words2, words3, words4):\n",
    "            w1 = w1.lower()\n",
    "            w2 = w2.lower()\n",
    "            w3 = w3.lower()\n",
    "            w4 = w4.lower()\n",
    "\n",
    "            # words remaining after reaching 100 will be removed selectively by hand\n",
    "            alternated_words.append(w1)\n",
    "            alternated_words.append(w2)\n",
    "            alternated_words.append(w3)\n",
    "            alternated_words.append(w4)\n",
    "\n",
    "        outfile.write(\"\\n\".join(alternated_words))\n",
    "\n",
    "print(\"Alternated words have been saved to:\", output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b811b24-7e24-409b-98a2-143fbabf0317",
   "metadata": {},
   "source": [
    "### ES_GGCTest_f (100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79aea412-9b8a-4ee5-b0e0-1c6405136e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alternated words have been saved to: ../data/sets_palabras/ES/gram/ES_GGCTest_f.txt\n"
     ]
    }
   ],
   "source": [
    "file1 = \"../data/sets_palabras/ES/gram/ES_NOUN_sg_f_test.txt\"\n",
    "file2 = \"../data/sets_palabras/ES/gram/ES_ADJ_pl_f_test.txt\"\n",
    "file3 = \"../data/sets_palabras/ES/gram/ES_NOUN_pl_f.txt\"\n",
    "file4 = \"../data/sets_palabras/ES/gram/ES_ADJ_sg_f_test.txt\"\n",
    "\n",
    "output_file = \"../data/sets_palabras/ES/gram/ES_GGCTest_f.txt\"\n",
    "\n",
    "with open(file1, \"r\", encoding=\"utf-8\") as f1, \\\n",
    "        open(file2, \"r\", encoding=\"utf-8\") as f2, \\\n",
    "        open(file3, \"r\", encoding=\"utf-8\") as f3, \\\n",
    "        open(file4, \"r\", encoding=\"utf-8\") as f4, \\\n",
    "        open(output_file, \"w\", encoding=\"utf-8\") as outfile:\n",
    "            \n",
    "        words1 = [line.strip() for line in f1 if line.strip()]\n",
    "        words2 = [line.strip() for line in f2 if line.strip()]\n",
    "        words3 = [line.strip() for line in f3 if line.strip()]\n",
    "        words4 = [line.strip() for line in f4 if line.strip()]\n",
    "    \n",
    "        alternated_words = []\n",
    "        for w1, w2, w3, w4 in zip(words1, words2, words3, words4):\n",
    "            w1 = w1.lower()\n",
    "            w2 = w2.lower()\n",
    "            w3 = w3.lower()\n",
    "            w4 = w4.lower()\n",
    "\n",
    "            # words remaining after reaching 100 will be removed selectively by hand\n",
    "            alternated_words.append(w1)\n",
    "            alternated_words.append(w2)\n",
    "            alternated_words.append(w3)\n",
    "            alternated_words.append(w4)\n",
    "\n",
    "        outfile.write(\"\\n\".join(alternated_words))\n",
    "\n",
    "print(\"Alternated words have been saved to:\", output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13aab7c3-687b-4b26-9e3b-941bf41c2763",
   "metadata": {},
   "source": [
    "## FRANTEXT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f6a76d-2ef3-4997-9937-f35b527255b9",
   "metadata": {},
   "source": [
    "Recherches Frantext: (\"un\"+[pos=\"NC|ADJ\"]) (\"une\"+[pos=\"NC|ADJ\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1aa2faa5-b897-4cd6-ae46-86a56d0a26c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"../data/sets_palabras/FR/gram/FRANTEXT_f.txt\"\n",
    "output_file = \"../data/sets_palabras/FR/gram/FR_gram_LDA_f.txt\"\n",
    "\n",
    "with open(input_file, 'r', encoding='utf-8') as infile, open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "            for line in infile:\n",
    "                parts = line.strip().split('\"')\n",
    "                if len(parts) > 5:\n",
    "                    word = parts[5].strip('\"')  \n",
    "                    outfile.write(word + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7203eea-a1ab-4705-93dd-780589170bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"../data/sets_palabras/FR/gram/FRANTEXT_m.txt\"\n",
    "output_file = \"../data/sets_palabras/FR/gram/FR_gram_LDA_m.txt\"\n",
    "\n",
    "with open(input_file, 'r', encoding='utf-8') as infile, open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "            for line in infile:\n",
    "                parts = line.strip().split('\"')\n",
    "                if len(parts) > 5:\n",
    "                    word = parts[5].strip('\"')  \n",
    "                    outfile.write(word + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c4634a-4e37-409a-a3cf-b6cfc3ca7758",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77d1de5d-d964-474a-beb3-15ca3ad5ed99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_translator import MyMemoryTranslator\n",
    "\n",
    "words = []\n",
    "count = 0\n",
    "with open(\"../data/sets_palabras/ES/ES_gram_fem_1000.txt\", \"r\", encoding='utf-8') as fr:\n",
    "    for line in fr:\n",
    "        word = line.strip()\n",
    "        count = count + 1\n",
    "                   \n",
    "        words.append(word)\n",
    "        \n",
    "        \n",
    "        if(count % 10 == 0):\n",
    "            with open(\"../data/sets_palabras/ES/temp.txt\", \"w\", encoding='utf-8') as fw:\n",
    "                for word in words:\n",
    "                    fw.write(word + \"\\n\")\n",
    "                    \n",
    "            words = []\n",
    "            \n",
    "            translated = MyMemoryTranslator(source='spanish', target='french').translate_file(\"../data/sets_palabras/ES/temp.txt\")\n",
    "            \n",
    "            with open(\"../data/sets_palabras/FR/FR_gram_fem_1000.txt\", \"a\", encoding='utf-8') as fw:\n",
    "                fw.write(\"\\n\")\n",
    "                fw.write(translated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47a83446-c6c9-4ac8-bf66-d4eeba6288dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_translator import MyMemoryTranslator\n",
    "\n",
    "words = []\n",
    "count = 0\n",
    "with open(\"../data/sets_palabras/ES/ES_gram_masc_1000.txt\", \"r\", encoding='utf-8') as fr:\n",
    "    for line in fr:\n",
    "        word = line.strip()\n",
    "        count = count + 1\n",
    "                   \n",
    "        words.append(word)\n",
    "        \n",
    "        \n",
    "        if(count % 10 == 0):\n",
    "            with open(\"../data/sets_palabras/ES/temp.txt\", \"w\", encoding='utf-8') as fw:\n",
    "                for word in words:\n",
    "                    fw.write(word + \"\\n\")\n",
    "                    \n",
    "            words = []\n",
    "            \n",
    "            translated = MyMemoryTranslator(source='spanish', target='french').translate_file(\"../data/sets_palabras/ES/temp.txt\")\n",
    "            \n",
    "            with open(\"../data/sets_palabras/FR/FR_gram_masc_1000.txt\", \"a\", encoding='utf-8') as fw:\n",
    "                fw.write(\"\\n\")\n",
    "                fw.write(translated)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
